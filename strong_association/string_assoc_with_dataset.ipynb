{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0727c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Frequent Itemsets:\n",
      "    support              itemsets\n",
      "0      0.6               (apple)\n",
      "1      0.9               (bread)\n",
      "2      0.8                (milk)\n",
      "3      0.4                (nuts)\n",
      "4      0.5        (apple, bread)\n",
      "5      0.5         (apple, milk)\n",
      "6      0.7         (bread, milk)\n",
      "7      0.4         (bread, nuts)\n",
      "8      0.4  (apple, bread, milk)\n",
      "\n",
      "ðŸ”— Strong Association Rules:\n",
      "       antecedents consequents  support  confidence      lift\n",
      "0         (apple)     (bread)      0.5    0.833333  0.925926\n",
      "1         (apple)      (milk)      0.5    0.833333  1.041667\n",
      "2         (bread)      (milk)      0.7    0.777778  0.972222\n",
      "3          (milk)     (bread)      0.7    0.875000  0.972222\n",
      "4          (nuts)     (bread)      0.4    1.000000  1.111111\n",
      "5  (apple, bread)      (milk)      0.4    0.800000  1.000000\n",
      "6   (apple, milk)     (bread)      0.4    0.800000  0.888889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load CSV file where each row is a transaction (comma-separated items)\n",
    "df = pd.read_csv('transactions.csv', header=None)\n",
    "transactions = df.values.tolist()\n",
    "\n",
    "# Remove NaNs and split items\n",
    "transactions = [[item for item in row if pd.notnull(item)] for row in transactions]\n",
    "\n",
    "# Encode transactions into a one-hot (binary) matrix\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "encoded_df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(encoded_df, min_support=0.4, use_colnames=True)\n",
    "print(\"ðŸ§¾ Frequent Itemsets:\\n\", frequent_itemsets)\n",
    "\n",
    "\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "rules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "print(\"\\nðŸ”— Strong Association Rules:\\n\", rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
